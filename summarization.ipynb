{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization Using Langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (0.3.27)\n",
      "Requirement already satisfied: groq in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (0.30.0)\n",
      "Requirement already satisfied: langchain-groq in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (0.3.6)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain) (0.3.72)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: sniffio in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: langchain-groq in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (0.3.6)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.68 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain-groq) (0.3.72)\n",
      "Requirement already satisfied: groq<1,>=0.29.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain-groq) (0.30.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from groq<1,>=0.29.0->langchain-groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from groq<1,>=0.29.0->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from groq<1,>=0.29.0->langchain-groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from groq<1,>=0.29.0->langchain-groq) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from groq<1,>=0.29.0->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from groq<1,>=0.29.0->langchain-groq) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from anyio<5,>=3.5.0->groq<1,>=0.29.0->langchain-groq) (3.10)\n",
      "Requirement already satisfied: certifi in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.29.0->langchain-groq) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.29.0->langchain-groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.29.0->langchain-groq) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-groq) (0.4.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-groq) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-groq) (6.0.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.68->langchain-groq) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain-groq) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.29.0->langchain-groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.29.0->langchain-groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.29.0->langchain-groq) (0.4.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-groq) (3.11.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-groq) (2.32.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-groq) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-groq) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-groq) (2.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain groq langchain-groq\n",
    "!pip install --upgrade langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic Prompt Summarization\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech=\"\"\"\n",
    "Machine learning and Python – a dream\n",
    "team\n",
    "The goal of machine learning is to teach machines (software) to carry out tasks by\n",
    "providing them a couple of examples (how to do or not do the task). Let's assume\n",
    "that each morning when you turn on your computer, you do the same task of\n",
    "moving e-mails around so that only e-mails belonging to the same topic end up in\n",
    "the same folder. After some time, you might feel bored and think of automating this\n",
    "chore. One way would be to start analyzing your brain and write down all rules\n",
    "your brain processes while you are shuffling your e-mails. However, this will be\n",
    "quite cumbersome and always imperfect. While you will miss some rules, you will\n",
    "over-specify others. A better and more future-proof way would be to automate this\n",
    "process by choosing a set of e-mail meta info and body/folder name pairs and let an\n",
    "algorithm come up with the best rule set. The pairs would be your training data, and\n",
    "the resulting rule set (also called model) could then be applied to future e-mails that\n",
    "we have not yet seen. This is machine learning in its simplest form.\n",
    "Of course, machine learning (often also referred to as Data Mining or Predictive\n",
    "Analysis) is not a brand new field in itself. Quite the contrary, its success over the\n",
    "recent years can be attributed to the pragmatic way of using rock-solid techniques\n",
    "and insights from other successful fields like statistics. There the purpose is for\n",
    "us humans to get insights into the data, for example, by learning more about the\n",
    "underlying patterns and relationships. As you read more and more about successful\n",
    "applications of machine learning (you have checked out www.kaggle.com already,\n",
    "haven't you?), you will see that applied statistics is a common field among machine\n",
    "learning experts.\n",
    "As you will see later, the process of coming up with a decent ML approach is never\n",
    "a waterfall-like process. Instead, you will see yourself going back and forth in your\n",
    "analysis, trying out different versions of your input data on diverse sets of ML\n",
    "algorithms. It is this explorative nature that lends itself perfectly to Python. Being\n",
    "an interpreted high-level programming language, it seems that Python has been\n",
    "designed exactly for this process of trying out different things. What is more, it\n",
    "does this even fast. Sure, it is slower than C or similar statically typed programming\n",
    "languages. Nevertheless, with the myriad of easy-to-use libraries that are often\n",
    "written in C, you don't have to sacrifice speed for agility.\n",
    "\n",
    "What the book will teach you\n",
    "(and what it will not)\n",
    "This book will give you a broad overview of what types of learning algorithms\n",
    "are currently most used in the diverse fields of machine learning, and where to\n",
    "watch out when applying them. From our own experience, however, we know that\n",
    "doing the \"cool\" stuff, that is, using and tweaking machine learning algorithms such\n",
    "as support vector machines, nearest neighbor search, or ensembles thereof, will\n",
    "only consume a tiny fraction of the overall time of a good machine learning expert.\n",
    "Looking at the following typical workflow, we see that most of the time will be spent\n",
    "in rather mundane tasks:\n",
    "Reading in the data and cleaning it\n",
    "Exploring and understanding the input data\n",
    "Analyzing how best to present the data to the learning algorithm\n",
    "Choosing the right model and learning algorithm\n",
    "Measuring the performance correctly\n",
    "When talking about exploring and understanding the input data, we will need a bit\n",
    "of statistics and basic math. However, while doing that, you will see that those topics\n",
    "that seemed to be so dry in your math class can actually be really exciting when you\n",
    "use them to look at interesting data.\n",
    "The journey starts when you read in the data. When you have to answer questions\n",
    "such as how to handle invalid or missing values, you will see that this is more an\n",
    "art than a precise science. And a very rewarding one, as doing this part right will\n",
    "open your data to more machine learning algorithms and thus increase the likelihood\n",
    "of success.\n",
    "With the data being ready in your program's data structures, you will want to get\n",
    "a real feeling of what animal you are working with. Do you have enough data to\n",
    "answer your questions? If not, you might want to think about additional ways to\n",
    "get more of it. Do you even have too much data? Then you probably want to think\n",
    "about how best to extract a sample of it.\n",
    "Often you will not feed the data directly into your machine learning algorithm.\n",
    "Instead you will find that you can refine parts of the data before training. Many times\n",
    "the machine learning algorithm will reward you with increased performance. You\n",
    "will even find that a simple algorithm with refined data generally outperforms a very\n",
    "sophisticated algorithm with raw data. This part of the machine learning workflow\n",
    "is called feature engineering, and is most of the time a very exciting and rewarding\n",
    "challenge. You will immediately see the results of being creative and intelligent.\n",
    "\n",
    "Choosing the right learning algorithm, then, is not simply a shootout of the three or\n",
    "four that are in your toolbox (there will be more you will see). It is more a thoughtful\n",
    "process of weighing different performance and functional requirements. Do you\n",
    "need a fast result and are willing to sacrifice quality? Or would you rather spend\n",
    "more time to get the best possible result? Do you have a clear idea of the future data\n",
    "or should you be a bit more conservative on that side?\n",
    "Finally, measuring the performance is the part where most mistakes are waiting for\n",
    "the aspiring machine learner. There are easy ones, such as testing your approach\n",
    "with the same data on which you have trained. But there are more difficult ones,\n",
    "when you have imbalanced training data. Again, data is the part that determines\n",
    "whether your undertaking will fail or succeed.\n",
    "We see that only the fourth point is dealing with the fancy algorithms. Nevertheless,\n",
    "we hope that this book will convince you that the other four tasks are not simply\n",
    "chores, but can be equally exciting. Our hope is that by the end of the book, you\n",
    "will have truly fallen in love with data instead of learning algorithms.\n",
    "To that end, we will not overwhelm you with the theoretical aspects of the diverse\n",
    "ML algorithms, as there are already excellent books in that area (you will find\n",
    "pointers in the Appendix). Instead, we will try to provide an intuition of the\n",
    "underlying approaches in the individual chapters—just enough for you to get the\n",
    "idea and be able to undertake your first steps. Hence, this book is by no means the\n",
    "definitive guide to machine learning. It is more of a starter kit. We hope that it ignites\n",
    "your curiosity enough to keep you eager in trying to learn more and more about this\n",
    "interesting field.\n",
    "In the rest of this chapter, we will set up and get to know the basic Python libraries\n",
    "NumPy and SciPy and then train our first machine learning using scikit-learn.\n",
    "During that endeavor, we will introduce basic ML concepts that will be used\n",
    "throughout the book. The rest of the chapters will then go into more detail through\n",
    "the five steps described earlier, highlighting different aspects of machine learning in\n",
    "Python using diverse application scenarios.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_messages=[\n",
    "    SystemMessage(content='You are an expert assistant with expertize in summarizing speeches'),\n",
    "    HumanMessage(content=f'Please provide a brief and concise summary of the following speech:\\n TEXT: {speech}')\n",
    "]\n",
    "\n",
    "\n",
    "llm = ChatGroq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),  # <-- this is important\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1547 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1547"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##total tokens\n",
    "llm.get_num_tokens(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8y/mwpz99s95db042xywny67_qc0000gn/T/ipykernel_28351/1441627176.py:1: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm(chat_messages).content\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here is a brief and concise summary of the speech:\\n\\nThe speech introduces machine learning as a way to teach machines to perform tasks by providing examples, and highlights its connection to statistics and data analysis. It emphasizes that machine learning is not just about using algorithms, but also about data preparation, exploration, and understanding. The speech outlines the typical workflow of a machine learning expert, which includes reading and cleaning data, exploring and understanding the data, choosing the right model and algorithm, measuring performance, and feature engineering. The book aims to provide a broad overview of machine learning algorithms and their applications, with a focus on the practical aspects of working with data, rather than just the theoretical aspects of the algorithms.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(chat_messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a brief and concise summary of the speech:\n",
      "\n",
      "The speech introduces machine learning and its goal of teaching machines to perform tasks by providing examples. It explains that machine learning is not a new field, but rather a pragmatic application of techniques from statistics and other fields. The speech highlights the importance of Python in machine learning due to its explorative nature and ease of use. The book aims to provide a broad overview of machine learning algorithms and their applications, but also emphasizes the importance of mundane tasks such as data cleaning, exploration, and feature engineering in the machine learning workflow. The speech concludes by outlining the structure of the book, which will cover the five steps of machine learning (reading in data, exploring and understanding data, presenting data to the algorithm, choosing the right model, and measuring performance) and introduce basic machine learning concepts using Python libraries such as NumPy, SciPy, and scikit-learn.\n"
     ]
    }
   ],
   "source": [
    "##get_summary\n",
    "print(llm(chat_messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_template='''\n",
    "Write a summary of the following speech:\n",
    "Speech : `{speech}`\n",
    "Translate the precise summary to {language}.\n",
    "\n",
    "'''\n",
    "prompt=PromptTemplate(\n",
    "    input_variables=['speech','language'],\n",
    "    template=generic_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWrite a summary of the following speech:\\nSpeech : `\\nMachine learning and Python – a dream\\nteam\\nThe goal of machine learning is to teach machines (software) to carry out tasks by\\nproviding them a couple of examples (how to do or not do the task). Let\\'s assume\\nthat each morning when you turn on your computer, you do the same task of\\nmoving e-mails around so that only e-mails belonging to the same topic end up in\\nthe same folder. After some time, you might feel bored and think of automating this\\nchore. One way would be to start analyzing your brain and write down all rules\\nyour brain processes while you are shuffling your e-mails. However, this will be\\nquite cumbersome and always imperfect. While you will miss some rules, you will\\nover-specify others. A better and more future-proof way would be to automate this\\nprocess by choosing a set of e-mail meta info and body/folder name pairs and let an\\nalgorithm come up with the best rule set. The pairs would be your training data, and\\nthe resulting rule set (also called model) could then be applied to future e-mails that\\nwe have not yet seen. This is machine learning in its simplest form.\\nOf course, machine learning (often also referred to as Data Mining or Predictive\\nAnalysis) is not a brand new field in itself. Quite the contrary, its success over the\\nrecent years can be attributed to the pragmatic way of using rock-solid techniques\\nand insights from other successful fields like statistics. There the purpose is for\\nus humans to get insights into the data, for example, by learning more about the\\nunderlying patterns and relationships. As you read more and more about successful\\napplications of machine learning (you have checked out www.kaggle.com already,\\nhaven\\'t you?), you will see that applied statistics is a common field among machine\\nlearning experts.\\nAs you will see later, the process of coming up with a decent ML approach is never\\na waterfall-like process. Instead, you will see yourself going back and forth in your\\nanalysis, trying out different versions of your input data on diverse sets of ML\\nalgorithms. It is this explorative nature that lends itself perfectly to Python. Being\\nan interpreted high-level programming language, it seems that Python has been\\ndesigned exactly for this process of trying out different things. What is more, it\\ndoes this even fast. Sure, it is slower than C or similar statically typed programming\\nlanguages. Nevertheless, with the myriad of easy-to-use libraries that are often\\nwritten in C, you don\\'t have to sacrifice speed for agility.\\n\\nWhat the book will teach you\\n(and what it will not)\\nThis book will give you a broad overview of what types of learning algorithms\\nare currently most used in the diverse fields of machine learning, and where to\\nwatch out when applying them. From our own experience, however, we know that\\ndoing the \"cool\" stuff, that is, using and tweaking machine learning algorithms such\\nas support vector machines, nearest neighbor search, or ensembles thereof, will\\nonly consume a tiny fraction of the overall time of a good machine learning expert.\\nLooking at the following typical workflow, we see that most of the time will be spent\\nin rather mundane tasks:\\nReading in the data and cleaning it\\nExploring and understanding the input data\\nAnalyzing how best to present the data to the learning algorithm\\nChoosing the right model and learning algorithm\\nMeasuring the performance correctly\\nWhen talking about exploring and understanding the input data, we will need a bit\\nof statistics and basic math. However, while doing that, you will see that those topics\\nthat seemed to be so dry in your math class can actually be really exciting when you\\nuse them to look at interesting data.\\nThe journey starts when you read in the data. When you have to answer questions\\nsuch as how to handle invalid or missing values, you will see that this is more an\\nart than a precise science. And a very rewarding one, as doing this part right will\\nopen your data to more machine learning algorithms and thus increase the likelihood\\nof success.\\nWith the data being ready in your program\\'s data structures, you will want to get\\na real feeling of what animal you are working with. Do you have enough data to\\nanswer your questions? If not, you might want to think about additional ways to\\nget more of it. Do you even have too much data? Then you probably want to think\\nabout how best to extract a sample of it.\\nOften you will not feed the data directly into your machine learning algorithm.\\nInstead you will find that you can refine parts of the data before training. Many times\\nthe machine learning algorithm will reward you with increased performance. You\\nwill even find that a simple algorithm with refined data generally outperforms a very\\nsophisticated algorithm with raw data. This part of the machine learning workflow\\nis called feature engineering, and is most of the time a very exciting and rewarding\\nchallenge. You will immediately see the results of being creative and intelligent.\\n\\nChoosing the right learning algorithm, then, is not simply a shootout of the three or\\nfour that are in your toolbox (there will be more you will see). It is more a thoughtful\\nprocess of weighing different performance and functional requirements. Do you\\nneed a fast result and are willing to sacrifice quality? Or would you rather spend\\nmore time to get the best possible result? Do you have a clear idea of the future data\\nor should you be a bit more conservative on that side?\\nFinally, measuring the performance is the part where most mistakes are waiting for\\nthe aspiring machine learner. There are easy ones, such as testing your approach\\nwith the same data on which you have trained. But there are more difficult ones,\\nwhen you have imbalanced training data. Again, data is the part that determines\\nwhether your undertaking will fail or succeed.\\nWe see that only the fourth point is dealing with the fancy algorithms. Nevertheless,\\nwe hope that this book will convince you that the other four tasks are not simply\\nchores, but can be equally exciting. Our hope is that by the end of the book, you\\nwill have truly fallen in love with data instead of learning algorithms.\\nTo that end, we will not overwhelm you with the theoretical aspects of the diverse\\nML algorithms, as there are already excellent books in that area (you will find\\npointers in the Appendix). Instead, we will try to provide an intuition of the\\nunderlying approaches in the individual chapters—just enough for you to get the\\nidea and be able to undertake your first steps. Hence, this book is by no means the\\ndefinitive guide to machine learning. It is more of a starter kit. We hope that it ignites\\nyour curiosity enough to keep you eager in trying to learn more and more about this\\ninteresting field.\\nIn the rest of this chapter, we will set up and get to know the basic Python libraries\\nNumPy and SciPy and then train our first machine learning using scikit-learn.\\nDuring that endeavor, we will introduce basic ML concepts that will be used\\nthroughout the book. The rest of the chapters will then go into more detail through\\nthe five steps described earlier, highlighting different aspects of machine learning in\\nPython using diverse application scenarios.\\n`\\nTranslate the precise summary to Hindi.\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(speech=speech,language='Hindi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_prompt=prompt.format(speech=speech,language='Hindi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1572"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(complete_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8y/mwpz99s95db042xywny67_qc0000gn/T/ipykernel_28351/2388982184.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
      "/var/folders/8y/mwpz99s95db042xywny67_qc0000gn/T/ipykernel_28351/2388982184.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  summary=llm_chain.run({'speech':speech,'language':'hindi'})\n"
     ]
    }
   ],
   "source": [
    "llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
    "summary=llm_chain.run({'speech':speech,'language':'hindi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is a summary of the speech:\\n\\n**English Summary**\\n\\nThe speech introduces the concept of machine learning and its relationship with Python. Machine learning is a field that enables machines to perform tasks by providing them with examples. The speech explains that machine learning is not a new field, but rather a pragmatic application of techniques from statistics and other fields. The process of machine learning involves exploring and understanding data, choosing the right algorithm, and measuring performance. The speech highlights that most of the time in machine learning is spent on mundane tasks such as data cleaning and feature engineering, rather than on the fancy algorithms. The book aims to provide a broad overview of machine learning algorithms and their applications, with a focus on the practical aspects of machine learning in Python.\\n\\n**Hindi Summary**\\n\\nमशीन लर्निंग और पायथन - एक सपन टीम\\nयह भाषण मशीन लर्निंग की अवधारणा और पायथन के साथ इसके संबंध की शुरुआत करता है। मशीन लर्निंग एक क्षेत्र है जो मशीनों को उदाहरण प्रदान करके कार्य करने में सक्षम बनाता है। भाषण बताता है कि मशीन लर्निंग एक नया क्षेत्र नहीं है, बल्कि सांख्यिकी और अन्य क्षेत्रों से तकनीकों का व्यावहारिक अनुप्रयोग है। मशीन लर्निंग की प्रक्रिया में डेटा की खोज और समझ, एल्गोरिदम का चयन और प्रदर्शन की माप शामिल है। भाषण यह बताता है कि मशीन लर्निंग में अधिकांश समय डेटा साफ करने और फीचर इंजीनियरिंग जैसे साधारण कार्यों पर व्यतीत होता है, न कि फैंसी एल्गोरिदम पर। पुस्तक मशीन लर्निंग एल्गोरिदम और उनके अनुप्रयोगों का एक व्यापक अवलोकन प्रदान करना चाहती है, पायथन में मशीन लर्निंग के व्यावहारिक पहलुओं पर ध्यान केंद्रित करते हुए।'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StuffDocumentChain Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the path of  pdf file/files.\n",
    "pdfreader = PdfReader('/Users/abhi45/Downloads/Text_summarization_method/for_summary.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "pdfreader = PdfReader('/Users/abhi45/Downloads/Text_summarization_method/for_summary.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Concatenate\n",
    "# read text from pdf\n",
    "text = ''\n",
    "for i, page in enumerate(pdfreader.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        text += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ 1 ]Getting Started with Python \\nMachine Learning\\nMachine learning teaches machines to learn to carry out tasks by themselves. It is \\nthat simple. The complexity comes with the details, and that is most likely the reason  \\nyou are reading this book.\\nMaybe you have too much data and too little insight. You hope that using  \\nmachine learning algorithms you can solve this challenge, so you started digging \\ninto the algorithms. But after some time you were puzzled: Which of the myriad  \\nof algorithms should you actually choose?\\nAlternatively, maybe you are in general interested in machine learning and for \\nsome time you have been reading blogs and articles about it. Everything seemed \\nto be magic and cool, so you started your exploration and fed some toy data into a \\ndecision tree or a support vector machine. However, after you successfully applied \\nit to some other data, you wondered: Was the whole setting right? Did you get the \\noptimal results? And how do you know whether there are no better algorithms? Or \\nwhether your data was the right one?\\nWelcome to the club! Both of us (authors) were at those stages looking for \\ninformation that tells the stories behind the theoretical textbooks about machine \\nlearning. It turned out that much of that information was \"black art\" not usually \\ntaught in standard text books. So in a sense, we wrote this book to our younger \\nselves. A book that not only gives a quick introduction into machine learning, but \\nalso teaches lessons we learned along the way. We hope that it will also give you a \\nsmoother entry to one of the most exciting fields in Computer Science.Getting Started with Python Machine Learning\\n[ 2 ]Machine learning and Python – a dream \\nteam\\nThe goal of machine learning is to teach machines (software) to carry out tasks by \\nproviding them a couple of examples (how to do or not do the task). Let\\'s assume \\nthat each morning when you turn on your computer, you do the same task of \\nmoving e-mails around so that only e-mails belonging to the same topic end up in \\nthe same folder. After some time, you might feel bored and think of automating this \\nchore. One way would be to start analyzing your brain and write down all rules \\nyour brain processes while you are shuffling your e-mails. However, this will be \\nquite cumbersome and always imperfect. While you will miss some rules, you will \\nover-specify others. A better and more future-proof way would be to automate this \\nprocess by choosing a set of e-mail meta info and body/folder name pairs and let an \\nalgorithm come up with the best rule set. The pairs would be your training data, and \\nthe resulting rule set (also called model) could then be applied to future e-mails that \\nwe have not yet seen. This is machine learning in its simplest form.\\nOf course, machine learning (often also referred to as Data Mining or Predictive \\nAnalysis) is not a brand new field in itself. Quite the contrary, its success over the \\nrecent years can be attributed to the pragmatic way of using rock-solid techniques \\nand insights from other successful fields like statistics. There the purpose is for \\nus humans to get insights into the data, for example, by learning more about the \\nunderlying patterns and relationships. As you read more and more about successful \\napplications of machine learning (you have checked out www.kaggle.com  already, \\nhaven\\'t you?), you will see that applied statistics is a common field among machine \\nlearning experts.\\nAs you will see later, the process of coming up with a decent ML approach is never \\na waterfall-like process. Instead, you will see yourself going back and forth in your \\nanalysis, trying out different versions of your input data on diverse sets of ML \\nalgorithms. It is this explorative nature that lends itself perfectly to Python. Being \\nan interpreted high-level programming language, it seems that Python has been \\ndesigned exactly for this process of trying out different things. What is more, it \\ndoes this even fast. Sure, it is slower than C or similar statically typed programming \\nlanguages. Nevertheless, with the myriad of easy-to-use libraries that are often \\nwritten in C, you don\\'t have to sacrifice speed for agility.[ 3 ]What the book will teach you  \\n(and what it will not)\\nThis book will give you a broad overview of what types of learning algorithms  \\nare currently most used in the diverse fields of machine learning, and where to \\nwatch out when applying them. From our own experience, however, we know that \\ndoing the \"cool\" stuff, that is, using and tweaking machine learning algorithms such \\nas support vector machines, nearest neighbor search, or ensembles thereof, will \\nonly consume a tiny fraction of the overall time of a good machine learning expert. \\nLooking at the following typical workflow, we see that most of the time will be spent \\nin rather mundane tasks:\\n• Reading in the data and cleaning it\\n• Exploring and understanding the input data\\n• Analyzing how best to present the data to the learning algorithm\\n• Choosing the right model and learning algorithm\\n• Measuring the performance correctly\\nWhen talking about exploring and understanding the input data, we will need a bit \\nof statistics and basic math. However, while doing that, you will see that those topics \\nthat seemed to be so dry in your math class can actually be really exciting when you \\nuse them to look at interesting data.\\nThe journey starts when you read in the data. When you have to answer questions \\nsuch as how to handle invalid or missing values, you will see that this is more an  \\nart than a precise science. And a very rewarding one, as doing this part right will \\nopen your data to more machine learning algorithms and thus increase the likelihood \\nof success.\\nWith the data being ready in your program\\'s data structures, you will want to get \\na real feeling of what animal you are working with. Do you have enough data to \\nanswer your questions? If not, you might want to think about additional ways to  \\nget more of it. Do you even have too much data? Then you probably want to think \\nabout how best to extract a sample of it.\\nOften you will not feed the data directly into your machine learning algorithm. \\nInstead you will find that you can refine parts of the data before training. Many times \\nthe machine learning algorithm will reward you with increased performance. You \\nwill even find that a simple algorithm with refined data generally outperforms a very \\nsophisticated algorithm with raw data. This part of the machine learning workflow \\nis called feature engineering , and is most of the time a very exciting and rewarding \\nchallenge. You will immediately see the results of being creative and intelligent.Getting Started with Python Machine Learning\\n[ 4 ]Choosing the right learning algorithm, then, is not simply a shootout of the three or \\nfour that are in your toolbox (there will be more you will see). It is more a thoughtful \\nprocess of weighing different performance and functional requirements. Do you \\nneed a fast result and are willing to sacrifice quality? Or would you rather spend \\nmore time to get the best possible result? Do you have a clear idea of the future data \\nor should you be a bit more conservative on that side?\\nFinally, measuring the performance is the part where most mistakes are waiting for \\nthe aspiring machine learner. There are easy ones, such as testing your approach \\nwith the same data on which you have trained. But there are more difficult ones, \\nwhen you have imbalanced training data. Again, data is the part that determines \\nwhether your undertaking will fail or succeed.\\nWe see that only the fourth point is dealing with the fancy algorithms. Nevertheless, \\nwe hope that this book will convince you that the other four tasks are not simply \\nchores, but can be equally exciting. Our hope is that by the end of the book, you  \\nwill have truly fallen in love with data instead of learning algorithms.\\nTo that end, we will not overwhelm you with the theoretical aspects of the diverse \\nML algorithms, as there are already excellent books in that area (you will find \\npointers in the Appendix). Instead, we will try to provide an intuition of the \\nunderlying approaches in the individual chapters—just enough for you to get the \\nidea and be able to undertake your first steps. Hence, this book is by no means the \\ndefinitive guide  to machine learning. It is more of a starter kit. We hope that it ignites \\nyour curiosity enough to keep you eager in trying to learn more and more about this \\ninteresting field.\\nIn the rest of this chapter, we will set up and get to know the basic Python libraries \\nNumPy and SciPy and then train our first machine learning using scikit-learn. \\nDuring that endeavor, we will introduce basic ML concepts that will be used \\nthroughout the book. The rest of the chapters will then go into more detail through \\nthe five steps described earlier, highlighting different aspects of machine learning in \\nPython using diverse application scenarios.\\nWhat to do when you are stuck\\nWe try to convey every idea necessary to reproduce the steps throughout this  \\nbook. Nevertheless, there will be situations where you are stuck. The reasons  \\nmight range from simple typos over odd combinations of package versions to \\nproblems in understanding.[ 5 ]In this situation, there are many different ways to get help. Most likely, your problem \\nwill already be raised and solved in the following excellent Q&A sites:\\nhttp://metaoptimize.com/qa : This  Q&A site is laser-focused on machine learning \\ntopics. For almost every question, it contains above average answers from machine \\nlearning experts. Even if you don\\'t have any questions, it is a good habit to check it \\nout every now and then and read through some of the answers.\\nhttp://stats.stackexchange.com : This Q&A site is named Cross Validated, \\nsimilar to MetaOptimize, but is focused more on statistical problems.\\nhttp://stackoverflow.com : This Q&A site is much like the previous ones,  \\nbut with broader focus on general programming topics. It contains, for example, \\nmore  questions on some of the packages that we will use in this book, such as  \\nSciPy or matplotlib.\\n#machinelearning  on https://freenode.net/ : This is the IRC channel focused \\non machine learning topics. It is a small but very active and helpful community of \\nmachine learning experts.\\nhttp://www.TwoToReal.com : This is the instant Q&A site written by  the authors to \\nsupport you in topics that don\\'t fit in any of the preceding buckets. If you post your \\nquestion, one of the authors will get an instant message if he is online and be drawn \\nin a chat with you.\\nAs stated in the beginning, this book tries to help you get started quickly on your \\nmachine learning journey. Therefore, we highly encourage you to build up your own \\nlist of machine learning related blogs and check them out regularly. This is the best \\nway to get to know what works and what doesn\\'t.\\nThe only blog we want to highlight right here (more in the Appendix) is http://\\nblog.kaggle.com , the blog of the Kaggle company, which is carrying out machine \\nlearning competitions. Typically, they encourage the  winners of the competitions to \\nwrite down how they approached the competition, what strategies did not work, and \\nhow they arrived at the winning strategy. Even if you don\\'t read anything else, this is \\na must.\\nGetting started\\nAssuming that you have Python already installed (everything at least as recent as 2.7 \\nshould be fine), we need to install NumPy and SciPy for numerica l operations, as well \\nas matplotlib for visualization.Getting Started with Python Machine Learning\\n[ 6 ]Introduction to NumPy, SciPy, and matplotlib\\nBefore we can talk about concrete machine learning algorithms, we have to talk \\nabout how best to store the data we will chew through. This is important as the most \\nadvanced learning algorithm will not be of any help to us if it will never finish. This \\nmay be simply because accessing the data is too slow. Or maybe its representation \\nforces the operating system to swap all day. Add to this that Python is an interpreted \\nlanguage (a highly optimized one, though) that is slow for many numerically \\nheavy algorithms compared to C or FORTRAN. So we might ask why on earth so \\nmany scientists and companies are betting their fortune on Python even in highly \\ncomputation-intensive areas?\\nThe answer is that, in Python, it is very easy to off-load number crunching tasks to \\nthe lower layer in the form of C or FORTRAN extensions. And that is exactly what \\nNumPy and  SciPy  do ( http://scipy.org/Download ). In this tandem, NumPy \\nprovides the support of highly optimized multidimensional arrays, which are the \\nbasic data structure of most state-of-the-art algorithms. SciPy uses those arrays to \\nprovide a set of fast numerical recipes. Finally, matplotlib ( http://matplotlib.\\norg/) is probably the most convenient and feature-rich library to plot high-quality \\ngraphs using Python.\\nInstalling Python\\nLuckily, for all  major operating systems, that is, Windows, Mac, and Linux, there \\nare targeted installers for NumPy, SciPy, and matplotlib. If you are unsure about \\nthe installation process, you might want to install Anaconda Python distribution \\n(which you can access at https://store.continuum.io/cshop/anaconda/ ), which \\nis driven by Travis Oliphant, a founding contributor of SciPy. What sets Anaconda \\napart from other distributions such as  Enthought Canopy (which you can download \\nfrom https://www.enthought.com/downloads/ ) or Python(x,y) (accessible at \\nhttp://code.google.com/p/pythonxy/wiki/Downloads ), is that Anaconda is \\nalready fully Python 3 compatible—the Python version we will be using throughout \\nthe book.\\nChewing data efficiently with NumPy and \\nintelligently with SciPy\\nLet\\'s walk quickly through  some basic NumPy examples and then take a look at \\nwhat SciPy provides on top of it. On the way, we will get our feet wet with plotting \\nusing the marvelous Matplotlib package.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='[ 1 ]Getting Started with Python \\nMachine Learning\\nMachine learning teaches machines to learn to carry out tasks by themselves. It is \\nthat simple. The complexity comes with the details, and that is most likely the reason  \\nyou are reading this book.\\nMaybe you have too much data and too little insight. You hope that using  \\nmachine learning algorithms you can solve this challenge, so you started digging \\ninto the algorithms. But after some time you were puzzled: Which of the myriad  \\nof algorithms should you actually choose?\\nAlternatively, maybe you are in general interested in machine learning and for \\nsome time you have been reading blogs and articles about it. Everything seemed \\nto be magic and cool, so you started your exploration and fed some toy data into a \\ndecision tree or a support vector machine. However, after you successfully applied \\nit to some other data, you wondered: Was the whole setting right? Did you get the \\noptimal results? And how do you know whether there are no better algorithms? Or \\nwhether your data was the right one?\\nWelcome to the club! Both of us (authors) were at those stages looking for \\ninformation that tells the stories behind the theoretical textbooks about machine \\nlearning. It turned out that much of that information was \"black art\" not usually \\ntaught in standard text books. So in a sense, we wrote this book to our younger \\nselves. A book that not only gives a quick introduction into machine learning, but \\nalso teaches lessons we learned along the way. We hope that it will also give you a \\nsmoother entry to one of the most exciting fields in Computer Science.Getting Started with Python Machine Learning\\n[ 2 ]Machine learning and Python – a dream \\nteam\\nThe goal of machine learning is to teach machines (software) to carry out tasks by \\nproviding them a couple of examples (how to do or not do the task). Let\\'s assume \\nthat each morning when you turn on your computer, you do the same task of \\nmoving e-mails around so that only e-mails belonging to the same topic end up in \\nthe same folder. After some time, you might feel bored and think of automating this \\nchore. One way would be to start analyzing your brain and write down all rules \\nyour brain processes while you are shuffling your e-mails. However, this will be \\nquite cumbersome and always imperfect. While you will miss some rules, you will \\nover-specify others. A better and more future-proof way would be to automate this \\nprocess by choosing a set of e-mail meta info and body/folder name pairs and let an \\nalgorithm come up with the best rule set. The pairs would be your training data, and \\nthe resulting rule set (also called model) could then be applied to future e-mails that \\nwe have not yet seen. This is machine learning in its simplest form.\\nOf course, machine learning (often also referred to as Data Mining or Predictive \\nAnalysis) is not a brand new field in itself. Quite the contrary, its success over the \\nrecent years can be attributed to the pragmatic way of using rock-solid techniques \\nand insights from other successful fields like statistics. There the purpose is for \\nus humans to get insights into the data, for example, by learning more about the \\nunderlying patterns and relationships. As you read more and more about successful \\napplications of machine learning (you have checked out www.kaggle.com  already, \\nhaven\\'t you?), you will see that applied statistics is a common field among machine \\nlearning experts.\\nAs you will see later, the process of coming up with a decent ML approach is never \\na waterfall-like process. Instead, you will see yourself going back and forth in your \\nanalysis, trying out different versions of your input data on diverse sets of ML \\nalgorithms. It is this explorative nature that lends itself perfectly to Python. Being \\nan interpreted high-level programming language, it seems that Python has been \\ndesigned exactly for this process of trying out different things. What is more, it \\ndoes this even fast. Sure, it is slower than C or similar statically typed programming \\nlanguages. Nevertheless, with the myriad of easy-to-use libraries that are often \\nwritten in C, you don\\'t have to sacrifice speed for agility.[ 3 ]What the book will teach you  \\n(and what it will not)\\nThis book will give you a broad overview of what types of learning algorithms  \\nare currently most used in the diverse fields of machine learning, and where to \\nwatch out when applying them. From our own experience, however, we know that \\ndoing the \"cool\" stuff, that is, using and tweaking machine learning algorithms such \\nas support vector machines, nearest neighbor search, or ensembles thereof, will \\nonly consume a tiny fraction of the overall time of a good machine learning expert. \\nLooking at the following typical workflow, we see that most of the time will be spent \\nin rather mundane tasks:\\n• Reading in the data and cleaning it\\n• Exploring and understanding the input data\\n• Analyzing how best to present the data to the learning algorithm\\n• Choosing the right model and learning algorithm\\n• Measuring the performance correctly\\nWhen talking about exploring and understanding the input data, we will need a bit \\nof statistics and basic math. However, while doing that, you will see that those topics \\nthat seemed to be so dry in your math class can actually be really exciting when you \\nuse them to look at interesting data.\\nThe journey starts when you read in the data. When you have to answer questions \\nsuch as how to handle invalid or missing values, you will see that this is more an  \\nart than a precise science. And a very rewarding one, as doing this part right will \\nopen your data to more machine learning algorithms and thus increase the likelihood \\nof success.\\nWith the data being ready in your program\\'s data structures, you will want to get \\na real feeling of what animal you are working with. Do you have enough data to \\nanswer your questions? If not, you might want to think about additional ways to  \\nget more of it. Do you even have too much data? Then you probably want to think \\nabout how best to extract a sample of it.\\nOften you will not feed the data directly into your machine learning algorithm. \\nInstead you will find that you can refine parts of the data before training. Many times \\nthe machine learning algorithm will reward you with increased performance. You \\nwill even find that a simple algorithm with refined data generally outperforms a very \\nsophisticated algorithm with raw data. This part of the machine learning workflow \\nis called feature engineering , and is most of the time a very exciting and rewarding \\nchallenge. You will immediately see the results of being creative and intelligent.Getting Started with Python Machine Learning\\n[ 4 ]Choosing the right learning algorithm, then, is not simply a shootout of the three or \\nfour that are in your toolbox (there will be more you will see). It is more a thoughtful \\nprocess of weighing different performance and functional requirements. Do you \\nneed a fast result and are willing to sacrifice quality? Or would you rather spend \\nmore time to get the best possible result? Do you have a clear idea of the future data \\nor should you be a bit more conservative on that side?\\nFinally, measuring the performance is the part where most mistakes are waiting for \\nthe aspiring machine learner. There are easy ones, such as testing your approach \\nwith the same data on which you have trained. But there are more difficult ones, \\nwhen you have imbalanced training data. Again, data is the part that determines \\nwhether your undertaking will fail or succeed.\\nWe see that only the fourth point is dealing with the fancy algorithms. Nevertheless, \\nwe hope that this book will convince you that the other four tasks are not simply \\nchores, but can be equally exciting. Our hope is that by the end of the book, you  \\nwill have truly fallen in love with data instead of learning algorithms.\\nTo that end, we will not overwhelm you with the theoretical aspects of the diverse \\nML algorithms, as there are already excellent books in that area (you will find \\npointers in the Appendix). Instead, we will try to provide an intuition of the \\nunderlying approaches in the individual chapters—just enough for you to get the \\nidea and be able to undertake your first steps. Hence, this book is by no means the \\ndefinitive guide  to machine learning. It is more of a starter kit. We hope that it ignites \\nyour curiosity enough to keep you eager in trying to learn more and more about this \\ninteresting field.\\nIn the rest of this chapter, we will set up and get to know the basic Python libraries \\nNumPy and SciPy and then train our first machine learning using scikit-learn. \\nDuring that endeavor, we will introduce basic ML concepts that will be used \\nthroughout the book. The rest of the chapters will then go into more detail through \\nthe five steps described earlier, highlighting different aspects of machine learning in \\nPython using diverse application scenarios.\\nWhat to do when you are stuck\\nWe try to convey every idea necessary to reproduce the steps throughout this  \\nbook. Nevertheless, there will be situations where you are stuck. The reasons  \\nmight range from simple typos over odd combinations of package versions to \\nproblems in understanding.[ 5 ]In this situation, there are many different ways to get help. Most likely, your problem \\nwill already be raised and solved in the following excellent Q&A sites:\\nhttp://metaoptimize.com/qa : This  Q&A site is laser-focused on machine learning \\ntopics. For almost every question, it contains above average answers from machine \\nlearning experts. Even if you don\\'t have any questions, it is a good habit to check it \\nout every now and then and read through some of the answers.\\nhttp://stats.stackexchange.com : This Q&A site is named Cross Validated, \\nsimilar to MetaOptimize, but is focused more on statistical problems.\\nhttp://stackoverflow.com : This Q&A site is much like the previous ones,  \\nbut with broader focus on general programming topics. It contains, for example, \\nmore  questions on some of the packages that we will use in this book, such as  \\nSciPy or matplotlib.\\n#machinelearning  on https://freenode.net/ : This is the IRC channel focused \\non machine learning topics. It is a small but very active and helpful community of \\nmachine learning experts.\\nhttp://www.TwoToReal.com : This is the instant Q&A site written by  the authors to \\nsupport you in topics that don\\'t fit in any of the preceding buckets. If you post your \\nquestion, one of the authors will get an instant message if he is online and be drawn \\nin a chat with you.\\nAs stated in the beginning, this book tries to help you get started quickly on your \\nmachine learning journey. Therefore, we highly encourage you to build up your own \\nlist of machine learning related blogs and check them out regularly. This is the best \\nway to get to know what works and what doesn\\'t.\\nThe only blog we want to highlight right here (more in the Appendix) is http://\\nblog.kaggle.com , the blog of the Kaggle company, which is carrying out machine \\nlearning competitions. Typically, they encourage the  winners of the competitions to \\nwrite down how they approached the competition, what strategies did not work, and \\nhow they arrived at the winning strategy. Even if you don\\'t read anything else, this is \\na must.\\nGetting started\\nAssuming that you have Python already installed (everything at least as recent as 2.7 \\nshould be fine), we need to install NumPy and SciPy for numerica l operations, as well \\nas matplotlib for visualization.Getting Started with Python Machine Learning\\n[ 6 ]Introduction to NumPy, SciPy, and matplotlib\\nBefore we can talk about concrete machine learning algorithms, we have to talk \\nabout how best to store the data we will chew through. This is important as the most \\nadvanced learning algorithm will not be of any help to us if it will never finish. This \\nmay be simply because accessing the data is too slow. Or maybe its representation \\nforces the operating system to swap all day. Add to this that Python is an interpreted \\nlanguage (a highly optimized one, though) that is slow for many numerically \\nheavy algorithms compared to C or FORTRAN. So we might ask why on earth so \\nmany scientists and companies are betting their fortune on Python even in highly \\ncomputation-intensive areas?\\nThe answer is that, in Python, it is very easy to off-load number crunching tasks to \\nthe lower layer in the form of C or FORTRAN extensions. And that is exactly what \\nNumPy and  SciPy  do ( http://scipy.org/Download ). In this tandem, NumPy \\nprovides the support of highly optimized multidimensional arrays, which are the \\nbasic data structure of most state-of-the-art algorithms. SciPy uses those arrays to \\nprovide a set of fast numerical recipes. Finally, matplotlib ( http://matplotlib.\\norg/) is probably the most convenient and feature-rich library to plot high-quality \\ngraphs using Python.\\nInstalling Python\\nLuckily, for all  major operating systems, that is, Windows, Mac, and Linux, there \\nare targeted installers for NumPy, SciPy, and matplotlib. If you are unsure about \\nthe installation process, you might want to install Anaconda Python distribution \\n(which you can access at https://store.continuum.io/cshop/anaconda/ ), which \\nis driven by Travis Oliphant, a founding contributor of SciPy. What sets Anaconda \\napart from other distributions such as  Enthought Canopy (which you can download \\nfrom https://www.enthought.com/downloads/ ) or Python(x,y) (accessible at \\nhttp://code.google.com/p/pythonxy/wiki/Downloads ), is that Anaconda is \\nalready fully Python 3 compatible—the Python version we will be using throughout \\nthe book.\\nChewing data efficiently with NumPy and \\nintelligently with SciPy\\nLet\\'s walk quickly through  some basic NumPy examples and then take a look at \\nwhat SciPy provides on top of it. On the way, we will get our feet wet with plotting \\nusing the marvelous Matplotlib package.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [Document(page_content=text)]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "\tmodel=\"llama3-70b-8192\",\n",
    "\ttemperature=0,\n",
    "\tmax_tokens=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain_community) (0.3.72)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain_community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain_community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain_community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain_community) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain_community) (0.4.8)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain_community) (2.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from requests<3,>=2->langchain_community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from requests<3,>=2->langchain_community) (2025.7.14)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain_community) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''Write a concise abstract summary of the following speech.\n",
    "Speech: `{text}`\n",
    "'''\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['text'],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type='stuff',\n",
    "    prompt=prompt,\n",
    "    verbose=False\n",
    ")\n",
    "output_summary = chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is a concise abstract summary of the speech:\\n\\nThis book introduces machine learning with Python, covering the basics of machine learning and its applications. The authors aim to provide a practical guide, focusing on the process of machine learning rather than just the algorithms. They emphasize the importance of data preparation, exploration, and feature engineering, and provide an overview of the types of learning algorithms used in machine learning. The book is designed to be a starter kit, providing an intuition of the underlying approaches and encouraging readers to learn more. The authors also introduce the basic Python libraries NumPy, SciPy, and matplotlib, which are essential for machine learning in Python.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing Large Documents Using Map Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the path of  pdf file/files.\n",
    "pdfreader = PdfReader('/Users/abhi45/Downloads/Text_summarization_method/for_summary.pdf')\n",
    "from typing_extensions import Concatenate\n",
    "# read text from pdf\n",
    "text = ''\n",
    "for i, page in enumerate(pdfreader.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        text += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "\tmodel=\"llama3-70b-8192\",\n",
    "\ttemperature=0,\n",
    "\tmax_tokens=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (4.54.0)\n",
      "Requirement already satisfied: filelock in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from transformers) (0.34.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/envs/env/lib/python3.13/site-packages (from requests->transformers) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3244"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splittting the text\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=20)\n",
    "chunks = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type='map_reduce',\n",
    "    verbose=False\n",
    ")\n",
    "summary = chain.run(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The authors introduce machine learning, aiming to provide a comprehensive and practical guide that focuses on the process, including data preparation and exploration, rather than just algorithms. The text also recommends online resources and provides instructions for getting started with Python machine learning, including installing necessary libraries such as NumPy, SciPy, and matplotlib.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Reduce With Custom Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_prompt=\"\"\"\n",
    "Please summarize the below speech:\n",
    "Speech:`{text}'\n",
    "Summary:\n",
    "\"\"\"\n",
    "map_prompt_template=PromptTemplate(input_variables=['text'],\n",
    "                                    template=chunks_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_combine_prompt='''\n",
    "Provide a final summary of the entire speech with these important points.\n",
    "Add a Generic Motivational Title,\n",
    "Start the precise summary with an introduction and provide the\n",
    "summary in number points for the speech.\n",
    "Speech: `{text}`\n",
    "'''\n",
    "final_combine_prompt_template=PromptTemplate(input_variables=['text'],\n",
    "                                             template=final_combine_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='map_reduce',\n",
    "    map_prompt=map_prompt_template,\n",
    "    combine_prompt=final_combine_prompt_template,\n",
    "    verbose=False\n",
    ")\n",
    "output = summary_chain.run(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Generic Motivational Title:** \"Unlocking the Power of Machine Learning with Python: A Beginner\\'s Journey\"\\n\\n**Summary:**\\n\\nIntroduction:\\nWelcome to the world of machine learning with Python! This speech introduces a comprehensive guide to getting started with machine learning, a field that enables machines to perform tasks on their own. The authors share their own experiences and provide a roadmap to navigate the complexities of machine learning, making it accessible to beginners.\\n\\n**Summary in Number Points:**\\n\\n1. **Machine Learning 101**: Machine learning is a pragmatic application of techniques from statistics and other fields, teaching machines to perform tasks on their own.\\n2. **The Importance of Data**: Exploring and understanding input data is crucial, as most time spent on machine learning projects is on mundane tasks like data cleaning, feature engineering, and measuring performance.\\n3. **The Five Steps of Machine Learning**: The book covers the essential steps: reading in data, exploring and understanding data, presenting data to the algorithm, choosing the right model, and measuring performance.\\n4. **A Starter Kit, Not a Definitive Guide**: The book aims to provide a broad overview of machine learning algorithms and encourage further learning, rather than being a comprehensive guide.\\n5. **Resources for Getting Help**: Q&A sites like MetaOptimize, Cross Validated, and Stack Overflow are available for when you get stuck.\\n6. **Learning Machine Learning with Python**: Online resources like IRC channel #machinelearning, TwoToReal.com, and machine learning blogs can help you get started.\\n7. **Essential Tools**: Install necessary libraries like NumPy, SciPy, and matplotlib for numerical operations and visualization.\\n8. **Introduction to Key Libraries**: NumPy provides optimized multidimensional arrays, SciPy offers fast numerical recipes, and matplotlib is a convenient library for plotting high-quality graphs.\\n9. **Getting Started with Python**: Use Anaconda Python distribution, which is fully Python 3 compatible and includes NumPy, SciPy, and matplotlib.\\n10. **Encouragement to Explore**: Build your own list of machine learning-related blogs and explore additional resources to continue learning and growing in the field of machine learning with Python.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RefineChain For Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"[ 1 ]Getting Started with Python \n",
      "Machine Learning\n",
      "Machine learning teaches machines to learn to carry out tasks by themselves. It is \n",
      "that simple. The complexity comes with the details, and that is most likely the reason  \n",
      "you are reading this book.\n",
      "Maybe you have too much data and too little insight. You hope that using  \n",
      "machine learning algorithms you can solve this challenge, so you started digging \n",
      "into the algorithms. But after some time you were puzzled: Which of the myriad  \n",
      "of algorithms should you actually choose?\n",
      "Alternatively, maybe you are in general interested in machine learning and for \n",
      "some time you have been reading blogs and articles about it. Everything seemed \n",
      "to be magic and cool, so you started your exploration and fed some toy data into a \n",
      "decision tree or a support vector machine. However, after you successfully applied \n",
      "it to some other data, you wondered: Was the whole setting right? Did you get the \n",
      "optimal results? And how do you know whether there are no better algorithms? Or \n",
      "whether your data was the right one?\n",
      "Welcome to the club! Both of us (authors) were at those stages looking for \n",
      "information that tells the stories behind the theoretical textbooks about machine \n",
      "learning. It turned out that much of that information was \"black art\" not usually \n",
      "taught in standard text books. So in a sense, we wrote this book to our younger \n",
      "selves. A book that not only gives a quick introduction into machine learning, but \n",
      "also teaches lessons we learned along the way. We hope that it will also give you a \n",
      "smoother entry to one of the most exciting fields in Computer Science.Getting Started with Python Machine Learning\n",
      "[ 2 ]Machine learning and Python – a dream \n",
      "team\n",
      "The goal of machine learning is to teach machines (software) to carry out tasks by \n",
      "providing them a couple of examples (how to do or not do the task). Let's assume \n",
      "that each morning when you turn on your computer, you do the same task of \n",
      "moving e-mails around so that only e-mails belonging to the same topic end up in \n",
      "the same folder. After some time, you might feel bored and think of automating this \n",
      "chore. One way would be to start analyzing your brain and write down all rules \n",
      "your brain processes while you are shuffling your e-mails. However, this will be \n",
      "quite cumbersome and always imperfect. While you will miss some rules, you will \n",
      "over-specify others. A better and more future-proof way would be to automate this \n",
      "process by choosing a set of e-mail meta info and body/folder name pairs and let an \n",
      "algorithm come up with the best rule set. The pairs would be your training data, and \n",
      "the resulting rule set (also called model) could then be applied to future e-mails that \n",
      "we have not yet seen. This is machine learning in its simplest form.\n",
      "Of course, machine learning (often also referred to as Data Mining or Predictive \n",
      "Analysis) is not a brand new field in itself. Quite the contrary, its success over the \n",
      "recent years can be attributed to the pragmatic way of using rock-solid techniques \n",
      "and insights from other successful fields like statistics. There the purpose is for \n",
      "us humans to get insights into the data, for example, by learning more about the \n",
      "underlying patterns and relationships. As you read more and more about successful \n",
      "applications of machine learning (you have checked out www.kaggle.com  already, \n",
      "haven't you?), you will see that applied statistics is a common field among machine \n",
      "learning experts.\n",
      "As you will see later, the process of coming up with a decent ML approach is never \n",
      "a waterfall-like process. Instead, you will see yourself going back and forth in your \n",
      "analysis, trying out different versions of your input data on diverse sets of ML \n",
      "algorithms. It is this explorative nature that lends itself perfectly to Python. Being \n",
      "an interpreted high-level programming language, it seems that Python has been \n",
      "designed exactly for this process of trying out different things. What is more, it \n",
      "does this even fast. Sure, it is slower than C or similar statically typed programming \n",
      "languages. Nevertheless, with the myriad of easy-to-use libraries that are often \n",
      "written in C, you don't have to sacrifice speed for agility.[ 3 ]What the book will teach you  \n",
      "(and what it will not)\n",
      "This book will give you a broad overview of what types of learning algorithms  \n",
      "are currently most used in the diverse fields of machine learning, and where to \n",
      "watch out when applying them. From our own experience, however, we know that \n",
      "doing the \"cool\" stuff, that is, using and tweaking machine learning algorithms such \n",
      "as support vector machines, nearest neighbor search, or ensembles thereof, will \n",
      "only consume a tiny fraction of the overall time of a good machine learning expert. \n",
      "Looking at the following typical workflow, we see that most of the time will be spent \n",
      "in rather mundane tasks:\n",
      "• Reading in the data and cleaning it\n",
      "• Exploring and understanding the input data\n",
      "• Analyzing how best to present the data to the learning algorithm\n",
      "• Choosing the right model and learning algorithm\n",
      "• Measuring the performance correctly\n",
      "When talking about exploring and understanding the input data, we will need a bit \n",
      "of statistics and basic math. However, while doing that, you will see that those topics \n",
      "that seemed to be so dry in your math class can actually be really exciting when you \n",
      "use them to look at interesting data.\n",
      "The journey starts when you read in the data. When you have to answer questions \n",
      "such as how to handle invalid or missing values, you will see that this is more an  \n",
      "art than a precise science. And a very rewarding one, as doing this part right will \n",
      "open your data to more machine learning algorithms and thus increase the likelihood \n",
      "of success.\n",
      "With the data being ready in your program's data structures, you will want to get \n",
      "a real feeling of what animal you are working with. Do you have enough data to \n",
      "answer your questions? If not, you might want to think about additional ways to  \n",
      "get more of it. Do you even have too much data? Then you probably want to think \n",
      "about how best to extract a sample of it.\n",
      "Often you will not feed the data directly into your machine learning algorithm. \n",
      "Instead you will find that you can refine parts of the data before training. Many times \n",
      "the machine learning algorithm will reward you with increased performance. You \n",
      "will even find that a simple algorithm with refined data generally outperforms a very \n",
      "sophisticated algorithm with raw data. This part of the machine learning workflow \n",
      "is called feature engineering , and is most of the time a very exciting and rewarding \n",
      "challenge. You will immediately see the results of being creative and intelligent.Getting Started with Python Machine Learning\n",
      "[ 4 ]Choosing the right learning algorithm, then, is not simply a shootout of the three or \n",
      "four that are in your toolbox (there will be more you will see). It is more a thoughtful \n",
      "process of weighing different performance and functional requirements. Do you \n",
      "need a fast result and are willing to sacrifice quality? Or would you rather spend \n",
      "more time to get the best possible result? Do you have a clear idea of the future data \n",
      "or should you be a bit more conservative on that side?\n",
      "Finally, measuring the performance is the part where most mistakes are waiting for \n",
      "the aspiring machine learner. There are easy ones, such as testing your approach \n",
      "with the same data on which you have trained. But there are more difficult ones, \n",
      "when you have imbalanced training data. Again, data is the part that determines \n",
      "whether your undertaking will fail or succeed.\n",
      "We see that only the fourth point is dealing with the fancy algorithms. Nevertheless, \n",
      "we hope that this book will convince you that the other four tasks are not simply \n",
      "chores, but can be equally exciting. Our hope is that by the end of the book, you  \n",
      "will have truly fallen in love with data instead of learning algorithms.\n",
      "To that end, we will not overwhelm you with the theoretical aspects of the diverse \n",
      "ML algorithms, as there are already excellent books in that area (you will find \n",
      "pointers in the Appendix). Instead, we will try to provide an intuition of the \n",
      "underlying approaches in the individual chapters—just enough for you to get the \n",
      "idea and be able to undertake your first steps. Hence, this book is by no means the \n",
      "definitive guide  to machine learning. It is more of a starter kit. We hope that it ignites \n",
      "your curiosity enough to keep you eager in trying to learn more and more about this \n",
      "interesting field.\n",
      "In the rest of this chapter, we will set up and get to know the basic Python libraries \n",
      "NumPy and SciPy and then train our first machine learning using scikit-learn. \n",
      "During that endeavor, we will introduce basic ML concepts that will be used \n",
      "throughout the book. The rest of the chapters will then go into more detail through \n",
      "the five steps described earlier, highlighting different aspects of machine learning in \n",
      "Python using diverse application scenarios.\n",
      "What to do when you are stuck\n",
      "We try to convey every idea necessary to reproduce the steps throughout this  \n",
      "book. Nevertheless, there will be situations where you are stuck. The reasons  \n",
      "might range from simple typos over odd combinations of package versions to \n",
      "problems in understanding.[ 5 ]In this situation, there are many different ways to get help. Most likely, your problem \n",
      "will already be raised and solved in the following excellent Q&A sites:\n",
      "http://metaoptimize.com/qa : This  Q&A site is laser-focused on machine learning \n",
      "topics. For almost every question, it contains above average answers from machine \n",
      "learning experts. Even if you don't have any questions, it is a good habit to check it \n",
      "out every now and then and read through some of the answers.\n",
      "http://stats.stackexchange.com : This Q&A site is named Cross Validated, \n",
      "similar to MetaOptimize, but is focused more on statistical problems.\n",
      "http://stackoverflow.com : This Q&A site is much like the previous ones,\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: The authors introduce the concept of machine learning, which teaches machines to perform tasks on their own. They acknowledge that the complexity of machine learning lies in its details, and that's why readers are likely reading the book. The authors share their own experiences of being puzzled by the numerous algorithms and unsure of which one to choose. They wrote the book to provide a comprehensive introduction to machine learning, covering not only the theoretical aspects but also the practical lessons they learned along the way. The book focuses on the process of machine learning, including data preparation, exploration, and feature engineering, rather than just the algorithms themselves. It aims to provide a broad overview of machine learning, highlighting the importance of data and the explorative nature of the field, and encouraging readers to fall in love with data rather than just learning algorithms.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "but with broader focus on general programming topics. It contains, for example, \n",
      "more  questions on some of the packages that we will use in this book, such as  \n",
      "SciPy or matplotlib.\n",
      "#machinelearning  on https://freenode.net/ : This is the IRC channel focused \n",
      "on machine learning topics. It is a small but very active and helpful community of \n",
      "machine learning experts.\n",
      "http://www.TwoToReal.com : This is the instant Q&A site written by  the authors to \n",
      "support you in topics that don't fit in any of the preceding buckets. If you post your \n",
      "question, one of the authors will get an instant message if he is online and be drawn \n",
      "in a chat with you.\n",
      "As stated in the beginning, this book tries to help you get started quickly on your \n",
      "machine learning journey. Therefore, we highly encourage you to build up your own \n",
      "list of machine learning related blogs and check them out regularly. This is the best \n",
      "way to get to know what works and what doesn't.\n",
      "The only blog we want to highlight right here (more in the Appendix) is http://\n",
      "blog.kaggle.com , the blog of the Kaggle company, which is carrying out machine \n",
      "learning competitions. Typically, they encourage the  winners of the competitions to \n",
      "write down how they approached the competition, what strategies did not work, and \n",
      "how they arrived at the winning strategy. Even if you don't read anything else, this is \n",
      "a must.\n",
      "Getting started\n",
      "Assuming that you have Python already installed (everything at least as recent as 2.7 \n",
      "should be fine), we need to install NumPy and SciPy for numerica l operations, as well \n",
      "as matplotlib for visualization.Getting Started with Python Machine Learning\n",
      "[ 6 ]Introduction to NumPy, SciPy, and matplotlib\n",
      "Before we can talk about concrete machine learning algorithms, we have to talk \n",
      "about how best to store the data we will chew through. This is important as the most \n",
      "advanced learning algorithm will not be of any help to us if it will never finish. This \n",
      "may be simply because accessing the data is too slow. Or maybe its representation \n",
      "forces the operating system to swap all day. Add to this that Python is an interpreted \n",
      "language (a highly optimized one, though) that is slow for many numerically \n",
      "heavy algorithms compared to C or FORTRAN. So we might ask why on earth so \n",
      "many scientists and companies are betting their fortune on Python even in highly \n",
      "computation-intensive areas?\n",
      "The answer is that, in Python, it is very easy to off-load number crunching tasks to \n",
      "the lower layer in the form of C or FORTRAN extensions. And that is exactly what \n",
      "NumPy and  SciPy  do ( http://scipy.org/Download ). In this tandem, NumPy \n",
      "provides the support of highly optimized multidimensional arrays, which are the \n",
      "basic data structure of most state-of-the-art algorithms. SciPy uses those arrays to \n",
      "provide a set of fast numerical recipes. Finally, matplotlib ( http://matplotlib.\n",
      "org/) is probably the most convenient and feature-rich library to plot high-quality \n",
      "graphs using Python.\n",
      "Installing Python\n",
      "Luckily, for all  major operating systems, that is, Windows, Mac, and Linux, there \n",
      "are targeted installers for NumPy, SciPy, and matplotlib. If you are unsure about \n",
      "the installation process, you might want to install Anaconda Python distribution \n",
      "(which you can access at https://store.continuum.io/cshop/anaconda/ ), which \n",
      "is driven by Travis Oliphant, a founding contributor of SciPy. What sets Anaconda \n",
      "apart from other distributions such as  Enthought Canopy (which you can download \n",
      "from https://www.enthought.com/downloads/ ) or Python(x,y) (accessible at \n",
      "http://code.google.com/p/pythonxy/wiki/Downloads ), is that Anaconda is \n",
      "already fully Python 3 compatible—the Python version we will be using throughout \n",
      "the book.\n",
      "Chewing data efficiently with NumPy and \n",
      "intelligently with SciPy\n",
      "Let's walk quickly through  some basic NumPy examples and then take a look at \n",
      "what SciPy provides on top of it. On the way, we will get our feet wet with plotting \n",
      "using the marvelous Matplotlib package.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='refine',\n",
    "    verbose=True\n",
    ")\n",
    "output_summary = chain.run(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the provided context, I refined the original summary as follows:\\n\\nThe authors introduce the concept of machine learning, which teaches machines to perform tasks on their own. They acknowledge that the complexity of machine learning lies in its details, and that's why readers are likely reading the book. The authors share their own experiences of being puzzled by the numerous algorithms and unsure of which one to choose. They wrote the book to provide a comprehensive introduction to machine learning, covering not only the theoretical aspects but also the practical lessons they learned along the way. The book focuses on the process of machine learning, including data preparation, exploration, and feature engineering, rather than just the algorithms themselves. It aims to provide a broad overview of machine learning, highlighting the importance of data and the explorative nature of the field, and encouraging readers to fall in love with data rather than just learning algorithms. Additionally, the book provides resources for further learning, including online communities, Q&A sites, and blogs, and guides readers on getting started with Python and essential libraries like NumPy, SciPy, and matplotlib for machine learning.\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
